{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "import theano\n",
      "\n",
      "import theano.tensor as T\n",
      "import lasagne\n",
      "import urllib2 #For downloading the sample text file. You won't need this if you are providing your own file.\n",
      "try:\n",
      "#     in_text = urllib2.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt').read()\n",
      "    #You can also use your own file\n",
      "    #The file must be a simple text file.\n",
      "    #Simply edit the file name below and uncomment the line.  \n",
      "    in_text = open('thesis.txt', 'r').read()\n",
      "    in_text = in_text.decode(\"utf-8-sig\").encode(\"utf-8\")\n",
      "except Exception as e:\n",
      "    print(\"Please verify the location of the input file/URL.\")\n",
      "    print(\"A sample txt file can be downloaded from https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
      "    raise IOError('Unable to Read Text')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "generation_phrase = \"The quick brown fox jumps\" #This phrase will be used as seed to generate text.\n",
      "\n",
      "#This snippet loads the text file and creates dictionaries to \n",
      "#encode characters into a vector-space representation and vice-versa. \n",
      "chars = list(set(in_text))\n",
      "data_size, vocab_size = len(in_text), len(chars)\n",
      "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
      "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
      "\n",
      "#Lasagne Seed for Reproducibility\n",
      "lasagne.random.set_rng(np.random.RandomState(1))\n",
      "\n",
      "# Sequence Length\n",
      "SEQ_LENGTH = 20\n",
      "\n",
      "# Number of units in the two hidden (LSTM) layers\n",
      "N_HIDDEN = 512\n",
      "\n",
      "# Optimization learning rate\n",
      "LEARNING_RATE = .01\n",
      "\n",
      "# All gradients above this will be clipped\n",
      "GRAD_CLIP = 100\n",
      "\n",
      "# How often should we check the output?\n",
      "PRINT_FREQ = 1000\n",
      "\n",
      "# Number of epochs to train the net\n",
      "NUM_EPOCHS = 50\n",
      "\n",
      "# Batch Size\n",
      "BATCH_SIZE = 128"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gen_data(p, batch_size = BATCH_SIZE, data=in_text, return_target=True):\n",
      "    '''\n",
      "    This function produces a semi-redundant batch of training samples from the location 'p' in the provided string (data).\n",
      "    For instance, assuming SEQ_LENGTH = 5 and p=0, the function would create batches of \n",
      "    5 characters of the string (starting from the 0th character and stepping by 1 for each semi-redundant batch)\n",
      "    as the input and the next character as the target.\n",
      "    To make this clear, let us look at a concrete example. Assume that SEQ_LENGTH = 5, p = 0 and BATCH_SIZE = 2\n",
      "    If the input string was \"The quick brown fox jumps over the lazy dog.\",\n",
      "    For the first data point,\n",
      "    x (the inputs to the neural network) would correspond to the encoding of 'T','h','e',' ','q'\n",
      "    y (the targets of the neural network) would be the encoding of 'u'\n",
      "    For the second point,\n",
      "    x (the inputs to the neural network) would correspond to the encoding of 'h','e',' ','q', 'u'\n",
      "    y (the targets of the neural network) would be the encoding of 'i'\n",
      "    The data points are then stacked (into a three-dimensional tensor of size (batch_size,SEQ_LENGTH,vocab_size))\n",
      "    and returned. \n",
      "    Notice that there is overlap of characters between the batches (hence the name, semi-redundant batch).\n",
      "    '''\n",
      "    x = np.zeros((batch_size,SEQ_LENGTH,vocab_size))\n",
      "    y = np.zeros((batch_size,vocab_size))\n",
      "\n",
      "    for n in range(batch_size):\n",
      "        ptr = n\n",
      "        for i in range(SEQ_LENGTH):\n",
      "            x[n,i,char_to_ix[data[p+ptr+i]]] = 1.0\n",
      "        if(return_target):\n",
      "            y[n,char_to_ix[data[p+ptr+SEQ_LENGTH]]] = 1.0\n",
      "    return x.astype('float32'), np.array(y,dtype='float32')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By setting the first and second dimensions to None, we allow\n",
      "# arbitrary minibatch sizes with arbitrary sequence lengths.\n",
      "# The number of feature dimensions is 2, as described above.\n",
      "l_in = lasagne.layers.InputLayer(shape=(None, None, vocab_size))\n",
      "\n",
      "gate_parameters = lasagne.layers.recurrent.Gate(\n",
      " W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
      " b=lasagne.init.Constant(0.))\n",
      "cell_parameters = lasagne.layers.recurrent.Gate(\n",
      " W_in=lasagne.init.Orthogonal(), W_hid=lasagne.init.Orthogonal(),\n",
      " # Setting W_cell to None denotes that no cell connection will be used.\n",
      " W_cell=None, b=lasagne.init.Constant(0.),\n",
      " # By convention, the cell nonlinearity is tanh in an LSTM.\n",
      " nonlinearity=lasagne.nonlinearities.tanh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We now build the LSTM layer which takes l_in as the input layer\n",
      "# We clip the gradients at GRAD_CLIP to prevent the problem of exploding gradients. \n",
      "\n",
      "l_forward_1 = lasagne.layers.recurrent.LSTMLayer(\n",
      "    l_in, N_HIDDEN, ingate=gate_parameters, forgetgate=gate_parameters,\n",
      "     cell=cell_parameters, outgate=gate_parameters,\n",
      "    grad_clipping=GRAD_CLIP,\n",
      "    learn_init=True)\n",
      "\n",
      "l_forward_2 = lasagne.layers.recurrent.LSTMLayer(\n",
      "    l_forward_1, N_HIDDEN, ingate=gate_parameters, forgetgate=gate_parameters,\n",
      "     cell=cell_parameters, outgate=gate_parameters,\n",
      "    grad_clipping=GRAD_CLIP,\n",
      "    learn_init=True)\n",
      "\n",
      "l_forward_slice = lasagne.layers.SliceLayer(l_forward_2, -1, 1)\n",
      "\n",
      "l_out = lasagne.layers.DenseLayer(l_forward_slice, num_units=vocab_size, \\\n",
      "                                  W = lasagne.init.Normal(), \\\n",
      "                                  nonlinearity=lasagne.nonlinearities.softmax)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Theano tensor for the targets\n",
      "target_values = T.matrix('target_output')\n",
      "\n",
      "# lasagne.layers.get_output produces a variable for the output of the net\n",
      "network_output = lasagne.layers.get_output(l_out)\n",
      "\n",
      "# The loss function is calculated as the mean of the (categorical) cross-entropy between the prediction and target.\n",
      "cost = T.nnet.binary_crossentropy(network_output,target_values).mean()\n",
      "\n",
      "# Retrieve all parameters from the network\n",
      "all_params = lasagne.layers.get_all_params(l_out,trainable=True)\n",
      "\n",
      "# Compute AdaGrad updates for training\n",
      "print(\"Computing updates ...\")\n",
      "# updates = lasagne.updates.adagrad(cost, all_params, LEARNING_RATE)\n",
      "updates = lasagne.updates.adam(cost, all_params)\n",
      "# Theano functions for training and computing cost\n",
      "print(\"Compiling functions ...\")\n",
      "train = theano.function([l_in.input_var, target_values], cost, updates=updates)\n",
      "compute_cost = theano.function([l_in.input_var, target_values], cost)\n",
      "\n",
      "# In order to generate text from the network, we need the probability distribution of the next character given\n",
      "# the state of the network and the input (a seed).\n",
      "# In order to produce the probability distribution of the prediction, we compile a function called probs. \n",
      "\n",
      "probs = theano.function([l_in.input_var],network_output)\n",
      "\n",
      "print(\"done\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def try_it_out(N=200,generation_phrase = generation_phrase):\n",
      "    '''\n",
      "    This function uses the user-provided string \"generation_phrase\" and current state of the RNN generate text.\n",
      "    The function works in three steps:\n",
      "    1. It converts the string set in \"generation_phrase\" (which must be over SEQ_LENGTH characters long) \n",
      "       to encoded format. We use the gen_data function for this. By providing the string and asking for a single batch,\n",
      "       we are converting the first SEQ_LENGTH characters into encoded form. \n",
      "    2. We then use the LSTM to predict the next character and store it in a (dynamic) list sample_ix. This is done by using the 'probs'\n",
      "       function which was compiled above. Simply put, given the output, we compute the probabilities of the target and pick the one \n",
      "       with the highest predicted probability. \n",
      "    3. Once this character has been predicted, we construct a new sequence using all but first characters of the \n",
      "       provided string and the predicted character. This sequence is then used to generate yet another character.\n",
      "       This process continues for \"N\" characters. \n",
      "    To make this clear, let us again look at a concrete example. \n",
      "    Assume that SEQ_LENGTH = 5 and generation_phrase = \"The quick brown fox jumps\". \n",
      "    We initially encode the first 5 characters ('T','h','e',' ','q'). The next character is then predicted (as explained in step 2). \n",
      "    Assume that this character was 'J'. We then construct a new sequence using the last 4 (=SEQ_LENGTH-1) characters of the previous\n",
      "    sequence ('h','e',' ','q') , and the predicted letter 'J'. This new sequence is then used to compute the next character and \n",
      "    the process continues.\n",
      "    '''\n",
      "\n",
      "    assert(len(generation_phrase)>=SEQ_LENGTH)\n",
      "    sample_ix = []\n",
      "    x,_ = gen_data(len(generation_phrase)-SEQ_LENGTH, 1, generation_phrase,0)\n",
      "\n",
      "    for i in range(N):\n",
      "        # Pick the character that got assigned the highest probability\n",
      "        ix = np.argmax(probs(x).ravel())\n",
      "        # Alternatively, to sample from the distribution instead:\n",
      "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
      "        sample_ix.append(ix)\n",
      "        x[:,0:SEQ_LENGTH-1,:] = x[:,1:,:]\n",
      "        x[:,SEQ_LENGTH-1,:] = 0.0\n",
      "        x[0,SEQ_LENGTH-1,sample_ix[-1]] = 1.0\n",
      "\n",
      "    random_snippet = generation_phrase + ''.join(ix_to_char[ix] for ix in sample_ix)    \n",
      "    print(\"----\\n %s \\n----\" % random_snippet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Training ...\")\n",
      "print(\"Seed used for text generation is: \" + generation_phrase)\n",
      "p = 0\n",
      "min_loss = 1.0\n",
      "try:\n",
      "    for it in xrange(data_size * NUM_EPOCHS / BATCH_SIZE):\n",
      "        try_it_out() # Generate text using the p^th character as the start. \n",
      "\n",
      "        avg_cost = 0;\n",
      "        for _ in range(PRINT_FREQ):\n",
      "            x,y = gen_data(p)\n",
      "\n",
      "            #print(p)\n",
      "            p += SEQ_LENGTH + BATCH_SIZE - 1 \n",
      "            if(p+BATCH_SIZE+SEQ_LENGTH >= data_size):\n",
      "                print('Carriage Return')\n",
      "                p = 0;\n",
      "            avg_cost += train(x, y)\n",
      "        print(\"Epoch {} average loss = {}\".format(it*1.0*PRINT_FREQ/data_size*BATCH_SIZE, avg_cost / PRINT_FREQ))\n",
      "        loss = avg_cost / PRINT_FREQ\n",
      "        if loss < min_loss:\n",
      "            np.savez(\"lstm_model_thesis_loss=min.npz\", *lasagne.layers.get_all_param_values(l_out))\n",
      "            min_loss = loss\n",
      "            \n",
      "except KeyboardInterrupt:\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training ...\n",
        "Seed used for text generation is: The quick brown fox jumps\n",
        "----\n",
        " The quick brown fox jumpserenting the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 0.0 average loss = 0.0376145002022"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsing the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sore the sor \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 0.213013458124 average loss = 0.0342325941548"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps and the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selman the selm \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 0.426026916247 average loss = 0.0317835644782"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps the concertion of the concertion of the concertion of the concertion of the concertion of the concertion of the concertion of the concertion of the concertion of the concertion of the concertion of t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 0.639040374371 average loss = 0.0290963192657"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the self of the  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 0.852053832495 average loss = 0.0285953994915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1.06506729062 average loss = 0.0274853540827"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the German strong the German strong the German strong the German strong the German strong the German strong the German strong the German strong the German strong the German strong the German stron \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1.27808074874 average loss = 0.0267046921793"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the formed the forme \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1.49109420687 average loss = 0.0248779424857"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the explanation of the explanation of the explanation of the explanation of the explanation of the explanation of the explanation of the explanation of the explanation of the explanation of the ex \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1.70410766499 average loss = 0.025100325698"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the superficial and the superficial and the superficial and the superficial and the superficial and the superficial and the superficial and the superficial and the superficial and the superficial  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1.91712112311 average loss = 0.02486234021"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps and more the word of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world of the world \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2.13013458124 average loss = 0.0246911660191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps and self such a strong the most problem of the same conception of the same conception of the same conception of the same conception of the same conception of the same conception of the same conceptio \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2.34314803936 average loss = 0.0230697647454"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps and the stronger constitutes and the stronger constitutes and the stronger constitutes and the stronger constitutes and the stronger constitutes and the stronger constitutes and the stronger constitu \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2.55616149748 average loss = 0.0234906575885"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and the saint, and t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2.76917495561 average loss = 0.023196934972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps and also an ancient and conscience and also an ancient and conscience and also an ancient and conscience and also an ancient and conscience and also an ancient and conscience and also an ancient and  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 2.98218841373 average loss = 0.0235522979163"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the same time and the standard of the same time and the standard of the same time and the standard of the same time and the standard of the same time and the standard of the same time and the stan \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 3.19520187186 average loss = 0.0218684318345"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the struggle of the  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 3.40821532998 average loss = 0.0222215975001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the same time to the same time to the same time to the same time to the same time to the same time to the same time to the same time to the same time to the same time to the same time to the same  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 3.6212287881 average loss = 0.0221328990459"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsions and self-desire, and all the problems of the seventh of the seventh of the seventh of the seventh of the seventh of the seventh of the seventh of the seventh of the seventh of the seventh of the  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 3.83424224623 average loss = 0.0224205661314"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the surmounting of the surmounting of the surmounting of the surmounting of the surmounting of the surmounting of the surmounting of the surmounting of the surmounting of the surmounting of the su \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4.04725570435 average loss = 0.0210159862954"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4.26026916247 average loss = 0.021168904487"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps to the same time that there is not there is not there is not there is not there is not there is not there is not there is not there is not there is not there is not there is not there is not there is \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4.4732826206 average loss = 0.0210939240744"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the present desire to the present desire to the present desire to the present desire to the present desire to the present desire to the present desire to the present desire to the present desire t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4.68629607872 average loss = 0.0211722026663"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the most poirt of the more refinement of the more refinement of the more refinement of the more refinement of the more refinement of the more refinement of the more refinement of the more refineme \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 4.89930953685 average loss = 0.0203675795682"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps in the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5.11232299497 average loss = 0.0200506677162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsions, and the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sens \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5.32533645309 average loss = 0.0200896651652"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsy of the present day and disclosed to the philosopher will be concerning the spirit of the present day and disclosed to the philosopher will be concerning the spirit of the present day and disclosed t \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5.53834991122 average loss = 0.0200719259428"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the most suffocates there is a condition of the most suffocates there is a condition of the most suffocates there is a condition of the most suffocates there is a condition of the most suffocates  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5.75136336934 average loss = 0.0194913830357"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps of the same.\n",
        "\n",
        "\n",
        "88\n",
        "\n",
        "=Prevention of the same.\n",
        "\n",
        "\n",
        "88\n",
        "\n",
        "=Prevention of the same.\n",
        "\n",
        "\n",
        "88\n",
        "\n",
        "=Prevention of the same.\n",
        "\n",
        "\n",
        "88\n",
        "\n",
        "=Prevention of the same.\n",
        "\n",
        "\n",
        "88\n",
        "\n",
        "=Prevention of the same.\n",
        "\n",
        "\n",
        "88\n",
        "\n",
        "=Prevention of the same.\n",
        " \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 5.96437682746 average loss = 0.0189485998601"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps intercourse with an ancient and exceptional conscience and the sense of the same time a definite and more placed, and the contention of the same time a definite and more placed, and the contention of \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 6.17739028559 average loss = 0.0191436422328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsy--and therefore in the spirit and stronger than to be discovered to read and stronger than to be discovered to read and stronger than to be discovered to read and stronger than to be discovered to re \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 6.39040374371 average loss = 0.0189652287764"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsion, and supposed to the expression of the same assurance of all the more respect, the self-deceive of the same assurance of all the more respect, the self-deceive of the same assurance of all the mor \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 6.60341720184 average loss = 0.0185210376708"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps and the consequence of love and the consequence of love and the consequence of love and the consequence of love and the consequence of love and the consequence of love and the consequence of love and \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 6.81643065996 average loss = 0.0179515729239"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsy--and the common of the common sunsend, the common of the common sunsend, the common of the common sunsend, the common of the common sunsend, the common of the common sunsend, the common of the commo \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 7.02944411808 average loss = 0.0181684423601"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps or desires to proves the philosopher and distrust and decestive of the present day, and the present day, and the present day, and the present day, and the present day, and the present day, and the pr \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 7.24245757621 average loss = 0.0180301217847"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsys, and the morality of the strength and despised, and the morality of the strength and despised, and the morality of the strength and despised, and the morality of the strength and despised, and the  \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 7.45547103433 average loss = 0.0175262662238"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps in the soul as the\n",
        "powerful or a depression that the strength of the soul as the\n",
        "powerful or a depression that the strength of the soul as the\n",
        "powerful or a depression that the strength of the soul a \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Carriage Return"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 7.66848449245 average loss = 0.0171416861424"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsion that the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 7.88149795058 average loss = 0.0171833957322"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps, always a more respect to the person of the subject of the community as the self-contrary of the community as the self-contrary of the community as the self-contrary of the community as the self-cont \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 8.0945114087 average loss = 0.0171470141588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumpsy of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the soul of the \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 8.30752486682 average loss = nan"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "----\n",
        " The quick brown fox jumps\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \n",
        "----"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "lstm_model_loss=0.0171416861424.npz  lstm_model_loss=0.0185210376708.npz  lstm_text_AWS.ipynb\r\n",
        "lstm_model_loss=0.0171470141588.npz  lstm_model_loss=0.0189485998601.npz  lstm_text.ipynb\r\n",
        "lstm_model_loss=0.0171833957322.npz  lstm_model_loss=0.0189652287764.npz  lstm_tuto.ipynb\r\n",
        "lstm_model_loss=0.0175262662238.npz  lstm_model_loss=0.0191436422328.npz  recurrent.py\r\n",
        "lstm_model_loss=0.0179515729239.npz  lstm_model_loss=0.0194913830357.npz  recurrent.pyc\r\n",
        "lstm_model_loss=0.0180301217847.npz  lstm_model_loss=nan.npz\r\n",
        "lstm_model_loss=0.0181684423601.npz  lstm_model.npz\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with np.load('lstm_model_loss=0.0171833957322.npz') as f:\n",
      "     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
      "lasagne.layers.set_all_param_values(l_out, param_values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try_it_out(generation_phrase = 'the the the the the the the')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "----\n",
        " the the the the the the theologians and self-reliance and self-reliance of the perspective of the subject of the community as the self-contrary of the community as the self-contrary of the community as the self-contrary of the  \n",
        "----\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}